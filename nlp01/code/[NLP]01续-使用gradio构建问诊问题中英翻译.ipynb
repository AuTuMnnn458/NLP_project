{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e664bd11",
   "metadata": {},
   "source": [
    "## 模型准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "486a29fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'D:/model/web/nlp01/ckpt/checkpoint-3070/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db7bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0ea7956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\env1\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d013a8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarianMTModel(\n",
       "  (model): MarianModel(\n",
       "    (shared): Embedding(65001, 512, padding_idx=65000)\n",
       "    (encoder): MarianEncoder(\n",
       "      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): SiLU()\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): MarianDecoder(\n",
       "      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): SiLU()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=65001, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06182fac",
   "metadata": {},
   "source": [
    "## 模型推理自己的写法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ed3c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '您的胸痛伴有以下任何症状吗?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40bd2daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(text, return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc5f1f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.generate(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7d9265b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([65000,   147,    37,    53,   189,     4,     3,   414, 37051,    27,\n",
       "          168, 31542, 10883,    23,     0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d17eaee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_text = tokenizer.decode(result[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8bb638e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'do you have any of the following symptoms with your chest pain?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ce0c20",
   "metadata": {},
   "source": [
    "## pipeline写法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1dc0e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "814bdc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zh2en = pipeline('translation_zh_to_en', \n",
    "                 model=model, \n",
    "                 tokenizer=tokenizer,\n",
    "                 device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "624f082e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'do you have any of the following symptoms with your chest pain?'}]\n"
     ]
    }
   ],
   "source": [
    "print(zh2en(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea4d6d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do you have any of the following symptoms with your chest pain?\n"
     ]
    }
   ],
   "source": [
    "print(zh2en(text)[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c79974",
   "metadata": {},
   "source": [
    "## 用gradio搭建前端"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "965b0506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "224170c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input):\n",
    "    return zh2en(input)[0]['translation_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f97c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = gr.Interface(\n",
    "    fn = translate,\n",
    "    inputs = [gr.Textbox(label = '输入你的问题', lines=6)],\n",
    "    outputs = [gr.Textbox(label = '翻译结果', lines=3)],\n",
    "    title = '使用MarianMT模型微调实现问诊问题中英翻译',\n",
    "    description = \n",
    "    '''\n",
    "    本模型可以实现中英翻译，在左边的框中输入你想要翻译的句子，右方会显示翻译的结果。\\n\n",
    "    该模型已在`tico-19`上微调，可以解决较多的医学/疫情相关的问题。\\n\n",
    "    微调数据集为`tico-19`，使用的模型checkpoint为`checkpoint-3070`。\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8e12169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae51068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
