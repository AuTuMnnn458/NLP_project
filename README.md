# NLP_project

## 1. 微调Helsinki-NLP模型实现问诊问题中英翻译
使用Helsinki-NLP模型对数据tico-19进行微调，并使用gradio搭建前端简易翻译系统。文件存放于[nlp01]中。

## 2. 微调BERT模型实现中文地址要素解析
使用人工标注数据集微调bert-base-chinese实现中文地址要素解析。

## 3. 微调RoBERTa模型实现中医问题答案抽取
使用roberta-base-chinese-extractive-qa模型微调中医问题语料，实现答案抽取。

## 4. 使用BERT模型与pipeline实现快速股民评论情感分析
使用BERT模型的pipeline快速实现股民评论的情感分类。

## 5. 使用BiLSTM实现新冠疫情期间网民情绪识别
构建一个双向LSTM模型，实现新冠疫情期间网民评论的情绪识别。

## 6. 基于LoRA微调BERT实现影评情感分类
- 项目背景：在自然语言处理领域，基于BERT等预训练模型的情感分析虽成效显著，但全参数微调存在计算成本高、过拟合风险大等问题。本项目使用LoRA（低秩适配），通过对BERT模型进行轻量化微调，在IMDB电影评论情感分类数据上构建模型，从而探索小规模场景下NLP任务的模型微调。 
- 数据处理：在数据预处理时，采取常规的编码，补全长度和截断操作；加载预训练模型时引入LoRA参数，并对比引入前后的模型变化；最后在模型上进行训练和推理。
- 项目成果：对模型成功实现快速的轻量化微调，得到的模型在推理上表现较好。
